{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a39cffa4-395b-4173-86f7-b6f541c7df39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import LightGCN\n",
    "from torch_geometric.utils import from_networkx\n",
    "\n",
    "sys.path.append(\"../complexity_hunters/\")  # to make utils importable\n",
    "sys.path.append(\".\")  # to make utils importable\n",
    "sys.path.append(\"..\")  # to make utils importable\n",
    "\n",
    "import utils.data_worker\n",
    "import utils.consts\n",
    "\n",
    "from graph.graph import build_graph\n",
    "import igraph\n",
    "\n",
    "from complexity_hunters.extra_metrics import sets_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be0824e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting graph to PyTorch Geometric format\n"
     ]
    }
   ],
   "source": [
    "graph = pickle.load(open(\"../data/graph.pkl\", \"rb\"))\n",
    "\n",
    "print(\"Converting graph to PyTorch Geometric format\")\n",
    "data = from_networkx(graph)\n",
    "data.edge_index = data.edge_index.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5120ae36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LightGCN model\n",
    "class RecommendationModel(torch.nn.Module):\n",
    "    def __init__(self, num_users, num_questions, embedding_dim=64, num_layers=3):\n",
    "        super().__init__()\n",
    "        self.model = LightGCN(num_nodes=num_users + num_questions, num_layers=num_layers, embedding_dim=embedding_dim)\n",
    "        self.user_embeddings = torch.nn.Embedding(num_users, embedding_dim)\n",
    "        self.question_embeddings = torch.nn.Embedding(num_questions, embedding_dim)\n",
    "\n",
    "    def forward(self, edge_index):\n",
    "        return self.model(edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "401ce3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_nodes = [node for node in graph.nodes if graph.nodes[node][\"type\"] == \"user\"]\n",
    "question_nodes = [node for node in graph.nodes if graph.nodes[node][\"type\"] == \"question\"]\n",
    "\n",
    "user_mapping = {node: idx for idx, node in enumerate(user_nodes)}\n",
    "question_mapping = {node: idx + len(user_nodes) for idx, node in enumerate(question_nodes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f12c6b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = data.edge_index.clone()\n",
    "for idx in range(edge_index.shape[1]):\n",
    "    src, dst = edge_index[:, idx]\n",
    "    if src in user_mapping and dst in question_mapping:\n",
    "        edge_index[0, idx] = user_mapping[src]\n",
    "        edge_index[1, idx] = question_mapping[dst]\n",
    "\n",
    "num_users = len(user_nodes)\n",
    "num_questions = len(question_nodes)\n",
    "embedding_dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e878e899",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecommendationModel(num_users, num_questions, embedding_dim)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dbf226f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LightGCN\n",
      "Epoch 1, Loss: 0.48352372646331787\n",
      "Epoch 2, Loss: 0.44332265853881836\n",
      "Epoch 3, Loss: 0.4018734097480774\n",
      "Epoch 4, Loss: 0.3601300120353699\n",
      "Epoch 5, Loss: 0.31906142830848694\n",
      "Epoch 6, Loss: 0.27958106994628906\n",
      "Epoch 7, Loss: 0.24247674643993378\n",
      "Epoch 8, Loss: 0.20835445821285248\n",
      "Epoch 9, Loss: 0.17760665714740753\n",
      "Epoch 10, Loss: 0.15040938556194305\n"
     ]
    }
   ],
   "source": [
    "labels = torch.ones(edge_index.shape[1])\n",
    "\n",
    "print(\"Training LightGCN\")\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(edge_index)\n",
    "    loss = criterion(outputs.squeeze(), labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0829abdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Loading dataset ../data/Posts.xml...\n",
      "Making recommendations\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "678",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m brand_new_question \u001b[38;5;241m=\u001b[39m posts[posts\u001b[38;5;241m.\u001b[39mPostTypeId \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msample()\n\u001b[0;32m      5\u001b[0m brand_new_question_id \u001b[38;5;241m=\u001b[39m brand_new_question[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mId\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m----> 6\u001b[0m brand_new_question_idx \u001b[38;5;241m=\u001b[39m \u001b[43mquestion_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbrand_new_question_id\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m      9\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[1;31mKeyError\u001b[0m: 678"
     ]
    }
   ],
   "source": [
    "posts = utils.data_worker.load_dataset(utils.consts.POSTS_DATA_PATH)\n",
    "\n",
    "print(\"Making recommendations\")\n",
    "brand_new_question = posts[posts.PostTypeId == 1].sample()\n",
    "brand_new_question_id = brand_new_question[\"Id\"].values[0]\n",
    "brand_new_question_idx = question_mapping[brand_new_question_id]\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    question_embedding = model.question_embeddings(torch.tensor([brand_new_question_idx]))\n",
    "    user_embeddings = model.user_embeddings.weight\n",
    "    scores = torch.matmul(user_embeddings, question_embedding.T).squeeze()\n",
    "\n",
    "top_k = 5\n",
    "recommended_users = scores.topk(top_k).indices\n",
    "recommended_user_ids = [user_nodes[idx] for idx in recommended_users]\n",
    "print(f\"Recommended users for question {brand_new_question_id}: {recommended_user_ids}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
